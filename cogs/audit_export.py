"""
Audit Export Commands for Discord bot
Export all audit channel messages to CSV format
"""

import discord
from discord import app_commands
from discord.ext import commands
import csv
import io
import os
import re
from datetime import datetime, timezone, timedelta
from utils.config_manager import load_config, is_administrator


class AuditExport(commands.Cog):
    """Commands for exporting audit data"""
    
    def __init__(self, bot):
        self.bot = bot
    
    @app_commands.command(name="–≤—ã–≥—Ä—É–∑–∏—Ç—å-–∫–∞–¥—Ä–æ–≤—ã–π", description="–í—ã–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∫–∞–¥—Ä–æ–≤–æ–≥–æ –∞—É–¥–∏—Ç–∞ –≤ CSV —Ñ–∞–π–ª")
    @app_commands.describe(
        –Ω–∞—á–∏–Ω–∞—è_—Å="–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä: 01.01.2025)"
    )
    async def export_audit_command(
        self,
        interaction: discord.Interaction,
        –Ω–∞—á–∏–Ω–∞—è_—Å: str
    ):
        """Export audit channel messages to CSV file"""
        
        # Check admin permissions
        config = load_config()
        if not is_administrator(interaction.user, config):
            embed = discord.Embed(
                title="‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∞–≤",
                description="–≠—Ç–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º.",
                color=discord.Color.red()
            )
            await interaction.response.send_message(embed=embed, ephemeral=True)
            return
        
        # Parse start date
        try:
            start_date = datetime.strptime(–Ω–∞—á–∏–Ω–∞—è_—Å, "%d.%m.%Y")
            start_date = start_date.replace(tzinfo=timezone.utc)
        except ValueError:
            embed = discord.Embed(
                title="‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã",
                description="–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç –î–î.–ú–ú.–ì–ì–ì–ì (–Ω–∞–ø—Ä–∏–º–µ—Ä: 01.01.2025)",
                color=discord.Color.red()
            )
            await interaction.response.send_message(embed=embed, ephemeral=True)
            return
        
        # Get audit channel
        audit_channel_id = config.get('audit_channel')
        if not audit_channel_id:
            embed = discord.Embed(
                title="‚ùå –ö–∞–Ω–∞–ª –∞—É–¥–∏—Ç–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω",
                description="–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–∞–Ω–∞–ª –∞—É–¥–∏—Ç–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±–æ—Ç–∞.",
                color=discord.Color.red()
            )
            await interaction.response.send_message(embed=embed, ephemeral=True)
            return
        
        audit_channel = interaction.guild.get_channel(audit_channel_id)
        if not audit_channel:
            embed = discord.Embed(
                title="‚ùå –ö–∞–Ω–∞–ª –∞—É–¥–∏—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω",
                description="–ö–∞–Ω–∞–ª –∞—É–¥–∏—Ç–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –±–æ—Ç –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞.",
                color=discord.Color.red()
            )
            await interaction.response.send_message(embed=embed, ephemeral=True)
            return
        
        # Defer response as this will take time
        await interaction.response.defer(ephemeral=True)
        
        try:
            # Start processing
            embed = discord.Embed(
                title="üîÑ –ù–∞—á–∏–Ω–∞—é —ç–∫—Å–ø–æ—Ä—Ç –∫–∞–¥—Ä–æ–≤–æ–≥–æ –∞—É–¥–∏—Ç–∞",
                description=f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å–æ–æ–±—â–µ–Ω–∏—è —Å {–Ω–∞—á–∏–Ω–∞—è_—Å} –ø–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å...",
                color=discord.Color.blue()
            )
            progress_message = await interaction.followup.send(embed=embed, ephemeral=True)
            
            # Read and process messages
            audit_data = await self._process_audit_messages(
                audit_channel, start_date, progress_message
            )
            
            if not audit_data:
                embed = discord.Embed(
                    title="üìù –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞",
                    description="–ó–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –∫–∞–¥—Ä–æ–≤–æ–≥–æ –∞—É–¥–∏—Ç–∞.",
                    color=discord.Color.yellow()
                )
                await progress_message.edit(embed=embed)
                return
            
            # Create CSV file
            csv_filename = await self._create_csv_file(audit_data, –Ω–∞—á–∏–Ω–∞—è_—Å)
            
            # Update final status
            embed = discord.Embed(
                title="‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω",
                description=f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: **{len(audit_data)}**\n"
                           f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: `{csv_filename}`\n"
                           f"üìÖ –ü–µ—Ä–∏–æ–¥: —Å {–Ω–∞—á–∏–Ω–∞—è_—Å} –ø–æ {datetime.now().strftime('%d.%m.%Y')}",
                color=discord.Color.green()
            )
            await progress_message.edit(embed=embed)
            
        except Exception as e:
            print(f"Error in audit export: {e}")
            embed = discord.Embed(
                title="‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞",
                description=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {str(e)}",
                color=discord.Color.red()
            )
            await interaction.followup.send(embed=embed, ephemeral=True)
    
    async def _process_audit_messages(self, channel, start_date, progress_message):
        """Process all messages in audit channel and extract data"""
        audit_data = []
        processed_count = 0
          # Get messages after start date
        async for message in channel.history(after=start_date, limit=None, oldest_first=True):
            # Only process user messages (not bot or webhook)
            # Skip bot messages and webhook messages, process all user messages
            if message.author.bot or message.webhook_id:
                continue
                
            processed_count += 1
              # Update progress every 100 messages
            if processed_count % 100 == 0:
                embed = discord.Embed(
                    title="üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å–æ–æ–±—â–µ–Ω–∏—è",
                    description=f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: **{processed_count}** —Å–æ–æ–±—â–µ–Ω–∏–π\n"
                               f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: **{len(audit_data)}**\n"
                               f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {message.created_at.strftime('%d.%m.%Y %H:%M')}",
                    color=discord.Color.blue()
                )
                try:
                    await progress_message.edit(embed=embed)
                except:
                    pass  # Ignore if we can't update
              # Parse message content
            records = await self._parse_message_content(message)
            audit_data.extend(records)        
        # Final progress update
        embed = discord.Embed(
            title="üîÑ –ó–∞–≤–µ—Ä—à–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É",
            description=f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: **{processed_count}** —Å–æ–æ–±—â–µ–Ω–∏–π\n"
                       f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: **{len(audit_data)}**",
            color=discord.Color.blue()
        )
        try:
            await progress_message.edit(embed=embed)
        except:
            pass
        
        return audit_data
    
    async def _parse_message_content(self, message):
        """Parse message content and extract audit records"""
        records = []
        
        # Always try to parse text content first (for old and new formats)
        content = message.content.strip()
        if content:
            text_records = await self._parse_text_format(content, message)
            records.extend(text_records)
        
        # Also check embeds (even though we're focusing on user messages, 
        # some users might use embeds or the message might have both)
        if message.embeds:
            for embed in message.embeds:
                record = await self._parse_embed_format(embed, message)
                if record:
                    records.append(record)
        
        # If no structured data found but message exists, create basic record
        if not records and content:
            # Try to extract any name/static pattern as fallback
            basic_record = await self._parse_fallback_format(content, message)
            if basic_record:
                records.append(basic_record)
        
        return records
    
    async def _parse_embed_format(self, embed, message):
        """Parse new embed format messages"""
        record = {
            'timestamp': message.created_at.strftime('%d.%m.%Y %H:%M:%S'),
            'name_with_static': '',
            'name': '',
            'static': '',
            'action': '',
            'action_date': '',
            'department': '',
            'position': '',
            'rank': '',
            'discord_id': '',
            'dismissal_reason': '',
            'moderator': ''
        }
        
        # Extract data from embed fields
        for field in embed.fields:
            if "–ö–∞–¥—Ä–æ–≤—É—é –æ—Ç–ø–∏—Å–∞–ª" in field.name:
                record['moderator'] = field.value
            elif "–ò–º—è –§–∞–º–∏–ª–∏—è | 6 —Ü–∏—Ñ—Ä —Å—Ç–∞—Ç–∏–∫–∞" in field.name or "–ò–º—è –§–∞–º–∏–ª–∏—è | –°—Ç–∞—Ç–∏–∫" in field.name:
                record['name_with_static'] = field.value
                # Parse name and static
                match = re.search(r'^(.+?)\s*\|\s*(\d{2,3}-?\d{3})$', field.value)
                if match:
                    record['name'] = match.group(1).strip()
                    record['static'] = match.group(2).strip()
            elif "–î–µ–π—Å—Ç–≤–∏–µ" in field.name:
                record['action'] = field.value
            elif "–î–∞—Ç–∞ –î–µ–π—Å—Ç–≤–∏—è" in field.name:
                record['action_date'] = field.value
            elif "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ" in field.name:
                record['department'] = field.value
            elif "–î–æ–ª–∂–Ω–æ—Å—Ç—å" in field.name:
                record['position'] = field.value
            elif "–í–æ–∏–Ω—Å–∫–æ–µ –∑–≤–∞–Ω–∏–µ" in field.name:
                record['rank'] = field.value
            elif "–ü—Ä–∏—á–∏–Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è" in field.name or "–ü—Ä–∏—á–∏–Ω–∞" in field.name:
                record['dismissal_reason'] = field.value
        
        # Try to extract Discord ID from mentions in message content
        if message.content:
            discord_id_match = re.search(r'<@(\d+)>', message.content)
            if discord_id_match:
                record['discord_id'] = discord_id_match.group(1)
        
        return record if record['name_with_static'] or record['action'] else None

    async def _parse_text_format(self, content, message):
        """Parse various old text formats with improved regex patterns"""
        records = []
        lines = content.split('\n')
        
        # Improved universal patterns to catch more formats
        patterns = [
            # Pattern 1: Numbered lists "1. –ú–∞–∫—Å–∏–º –ú–∏–Ω—Ç–µ–ª–æ 558-439" (various separators)
            re.compile(r'^\d+\.\s*([–ê-–Ø–∞-—è–Å—ë\s]+?)\s*[|/\-\s]\s*(\d{2,3}-?\d{3})'),
            
            # Pattern 2: Direct name + static with separators "–ê—Ä–∏—Å—Ç–∞—Ä—Ö –ì—Ä–æ–º–æ–≤ | 564-269"
            re.compile(r'^([–ê-–Ø–∞-—è–Å—ë\s]+?)\s*[|/\-]\s*(\d{2,3}-?\d{3})(?:\s|$)'),
            
            # Pattern 3: Name + static + rank info "–ê–ª–µ–∫—Å–µ—è –ì–∞–≤—Ä–∏–ª–æ–≤–∞ | 252-351 | –°–µ—Ä–∂–∞–Ω—Ç - –°—Ç–∞—Ä—à–∏–π —Å–µ—Ä–∂–∞–Ω—Ç"
            re.compile(r'^([–ê-–Ø–∞-—è–Å—ë\s]+?)\s*\|\s*(\d{2,3}-?\d{3})\s*\|\s*(.+?)$'),
            
            # Pattern 4: Name and static with just spaces (careful matching)
            re.compile(r'^([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)\s+(\d{2,3}-?\d{3})(?:\s|$)'),
            
            # Pattern 5: Static first, then name with separators
            re.compile(r'^(\d{2,3}-?\d{3})\s*[|/\-]\s*([–ê-–Ø–∞-—è–Å—ë\s]+?)(?:\s|$)'),
            
            # Pattern 6: Multiple people on one line "–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ 123-456, –ü–µ—Ç—Ä –°–∏–¥–æ—Ä–æ–≤ 789-012"
            re.compile(r'([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)\s+(\d{2,3}-?\d{3})'),
            
            # Pattern 7: Any name + static combination (most flexible)
            re.compile(r'([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)\s*[|/\-,;\s]\s*(\d{2,3}-?\d{3})'),
            
            # Pattern 8: Static + name (reverse) with any separators
            re.compile(r'(\d{2,3}-?\d{3})\s*[|/\-,;\s]\s*([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)'),
        ]
        
        # Collect all people found in this message
        people_found = []
        action_context = ""
        date_context = ""
        
        # First pass: collect all people and context
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('-#'):
                # Check for date in -# format
                date_match = re.search(r'-#\s*(\d{2}\.\d{2}\.\d{4})', line)
                if date_match:
                    date_context = date_match.group(1)
                continue
            
            # Check for action context in headers
            if any(word in line.lower() for word in ["–ø–æ–≤—ã—à–µ–Ω", "—É–≤–æ–ª–µ–Ω", "–ø—Ä–∏–Ω—è—Ç", "–ø–µ—Ä–µ–≤–µ–¥–µ–Ω", "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω", "–ø–æ–Ω–∏–∂–µ–Ω"]):
                action_context = line
                continue
            
            # Check for date lines
            date_match = re.match(r'^(\d{2}\.\d{2}\.\d{4})$', line)
            if date_match:
                date_context = date_match.group(1)
                continue
            
            # Try all patterns and collect all matches from the line
            line_matches = []
            
            # Special handling for Pattern 3 (with rank info)
            pattern3_match = patterns[2].match(line)
            if pattern3_match:
                line_matches.append({
                    'name': pattern3_match.group(1).strip(),
                    'static': pattern3_match.group(2).strip(),
                    'rank_info': pattern3_match.group(3).strip()
                })
            else:
                # Try other patterns
                for i, pattern in enumerate(patterns):
                    if i == 2:  # Skip pattern 3, already handled
                        continue
                    
                    if i in [5, 6, 7]:  # Patterns that can find multiple matches
                        matches = pattern.findall(line)
                        for match in matches:
                            # Determine name and static based on pattern
                            if i in [4, 7] and re.match(r'\d', match[0]):  # Static first
                                name, static = match[1].strip(), match[0].strip()
                            else:  # Name first
                                name, static = match[0].strip(), match[1].strip()
                            
                            # Validate name (at least 2 words, reasonable length)
                            if (len(name.split()) >= 2 and 
                                len(name) >= 5 and len(name) <= 50 and
                                re.match(r'^[–ê-–Ø–∞-—è–Å—ë\s]+$', name)):
                                line_matches.append({
                                    'name': name,
                                    'static': static,
                                    'rank_info': None
                                })
                    else:  # Patterns that find single match
                        match = pattern.match(line)
                        if match:
                            # Determine name and static
                            if i == 4 and re.match(r'\d', match.group(1)):  # Pattern 5: static first
                                name, static = match.group(2).strip(), match.group(1).strip()
                            else:
                                name, static = match.group(1).strip(), match.group(2).strip()
                            
                            # Validate name
                            if (len(name.split()) >= 2 and 
                                len(name) >= 5 and len(name) <= 50 and
                                re.match(r'^[–ê-–Ø–∞-—è–Å—ë\s]+$', name)):
                                line_matches.append({
                                    'name': name,
                                    'static': static,
                                    'rank_info': None
                                })
                            break  # Take first successful match for single-match patterns
            
            # Add all valid matches from this line
            people_found.extend(line_matches)
              # Also check for additional action info for existing people
            if line and people_found and not line_matches:
                if any(word in line.lower() for word in ["—É–≤–æ–ª–µ–Ω", "–ø–æ–≤—ã—à–µ–Ω", "–ø–æ–ª—É—á–∏–ª –∑–≤–∞–Ω–∏–µ", "–ø–µ—Ä–µ–≤–µ–¥–µ–Ω", "–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω", "–ø–æ–Ω–∏–∂–µ–Ω"]):
                    action_context = line
        
        # Second pass: create records for all found people (with deduplication)
        seen_people = set()
        for person in people_found:
            # Create unique identifier for deduplication
            person_id = f"{person['name'].lower()}|{person['static']}"
            if person_id in seen_people:
                continue  # Skip duplicates
            seen_people.add(person_id)
            
            record = self._create_base_record(message)
            record['name'] = person['name']
            record['static'] = person['static']
            record['name_with_static'] = f"{record['name']} | {record['static']}"
            record['action_date'] = date_context
            
            # Determine action
            if person['rank_info']:
                # Has rank change info
                rank_change = person['rank_info']
                if " - " in rank_change:
                    old_rank, new_rank = rank_change.split(" - ", 1)
                    record['action'] = f"–ü–æ–≤—ã—à–µ–Ω–∏–µ: {old_rank.strip()} ‚Üí {new_rank.strip()}"
                    record['rank'] = new_rank.strip()
                else:
                    record['action'] = rank_change
            elif action_context:
                # Use context action
                if "—É–≤–æ–ª–µ–Ω" in action_context.lower():
                    record['action'] = "–£–≤–æ–ª–µ–Ω —Å–æ —Å–ª—É–∂–±—ã"
                    record['dismissal_reason'] = action_context
                elif "–ø–æ–≤—ã—à–µ–Ω" in action_context.lower():
                    record['action'] = action_context
                elif "–ø—Ä–∏–Ω—è—Ç" in action_context.lower():
                    record['action'] = "–ü—Ä–∏–Ω—è—Ç –Ω–∞ —Å–ª—É–∂–±—É"
                else:
                    record['action'] = action_context
            else:
                # Fallback
                record['action'] = "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"
            
            records.append(record)
        
        return records
    
    def _create_base_record(self, message):
        """Create base record structure"""
        return {
            'timestamp': message.created_at.strftime('%d.%m.%Y %H:%M:%S'),
            'name_with_static': '',
            'name': '',
            'static': '',
            'action': '',
            'action_date': '',
            'department': '',
            'position': '',
            'rank': '',
            'discord_id': '',
            'dismissal_reason': '',
            'moderator': message.author.display_name
        }
    
    async def _create_csv_file(self, audit_data, start_date_str):
        """Create CSV file with audit data"""
        # Ensure exports directory exists
        exports_dir = os.path.join("data", "exports")
        os.makedirs(exports_dir, exist_ok=True)
        
        # Generate filename
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"audit_export_{start_date_str.replace('.', '-')}_{timestamp}.csv"
        filepath = os.path.join(exports_dir, filename)
        
        # CSV headers
        headers = [
            '–û—Ç–º–µ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏',
            '–ò–º—è –§–∞–º–∏–ª–∏—è | 6 —Ü–∏—Ñ—Ä —Å—Ç–∞—Ç–∏–∫–∞',
            '–ò–º—è –§–∞–º–∏–ª–∏—è',
            '–°—Ç–∞—Ç–∏–∫',
            '–î–µ–π—Å—Ç–≤–∏–µ',
            '–î–∞—Ç–∞ –î–µ–π—Å—Ç–≤–∏—è',
            '–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ',
            '–î–æ–ª–∂–Ω–æ—Å—Ç—å',
            '–ó–≤–∞–Ω–∏–µ',
            'Discord ID –±–æ–π—Ü–∞',
            '–ü—Ä–∏—á–∏–Ω–∞ —É–≤–æ–ª—å–Ω–µ–Ω–∏—è',
            '–ö–∞–¥—Ä–æ–≤—É—é –æ—Ç–ø–∏—Å–∞–ª'
        ]
        
        # Write CSV file
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)
            
            for record in audit_data:
                writer.writerow([
                    record.get('timestamp', ''),
                    record.get('name_with_static', ''),
                    record.get('name', ''),
                    record.get('static', ''),
                    record.get('action', ''),
                    record.get('action_date', ''),
                    record.get('department', ''),
                    record.get('position', ''),
                    record.get('rank', ''),
                    record.get('discord_id', ''),
                    record.get('dismissal_reason', ''),
                    record.get('moderator', '')
                ])
        
        return filename

    async def _parse_fallback_format(self, content, message):
        """Parse any remaining text that might contain personnel data as fallback"""
        # Enhanced patterns for better fallback parsing
        patterns = [
            # Standard separators with –Å support
            r'([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)\s*[|/\-]\s*(\d{2,3}-?\d{3})',
            r'([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)\s+(\d{2,3}-?\d{3})',
            r'(\d{2,3}-?\d{3})\s*[|/\-]\s*([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)',
            r'(\d{2,3}-?\d{3})\s+([–ê-–Ø–∞-—è–Å—ë]+(?:\s+[–ê-–Ø–∞-—è–Å—ë]+)+)',
            
            # Special punctuation patterns
            r'([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)\s*[:,;]\s*(\d{2,3}-?\d{3})',
            r'(\d{2,3}-?\d{3})\s*[:,;]\s*([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)',
            
            # Parentheses patterns
            r'([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)\s*\(\s*(\d{2,3}-?\d{3})\s*\)',
            r'\(\s*(\d{2,3}-?\d{3})\s*\)\s*([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)',
            
            # Dash patterns (various types)
            r'([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)\s*[‚Äî‚Äì\-]\s*(\d{2,3}-?\d{3})',
            r'(\d{2,3}-?\d{3})\s*[‚Äî‚Äì\-]\s*([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)',
            
            # Multiple space patterns
            r'([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)\s{2,}(\d{2,3}-?\d{3})',
            r'(\d{2,3}-?\d{3})\s{2,}([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)',
            
            # Dot patterns
            r'([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)\.\s*(\d{2,3}-?\d{3})',
            r'(\d{2,3}-?\d{3})\.\s*([–ê-–Ø–∞-—è–Å—ë]+\s+[–ê-–Ø–∞-—è–Å—ë]+)',
        ]
        
        all_matches = []
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            for match in matches:
                all_matches.append(match)
        
        if all_matches:
            # Validate and return the best match
            for match in all_matches:
                # Determine which group is name and which is static
                name, static = "", ""
                if re.match(r'\d', match[0]):  # First group starts with digit
                    static = match[0].strip()
                    name = match[1].strip()
                else:
                    name = match[0].strip()
                    static = match[1].strip()
                
                # Enhanced validation
                if (len(name.split()) >= 2 and  # At least first and last name
                    3 <= len(name) <= 50 and  # Reasonable name length
                    re.match(r'^\d{2,3}-?\d{3}$', static) and  # Valid static format
                    re.match(r'^[–ê-–Ø–∞-—è–Å—ë\s]+$', name) and  # Only Cyrillic and spaces
                    not re.search(r'\s{3,}', name)):  # No excessive spaces
                    
                    record = self._create_base_record(message)
                    record['name'] = name
                    record['static'] = static
                    record['name_with_static'] = f"{name} | {static}"
                    record['action'] = "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"
                    
                    return record
        
        return None

async def setup(bot):
    await bot.add_cog(AuditExport(bot))
